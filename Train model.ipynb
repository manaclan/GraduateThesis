{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1561997781660,
     "user": {
      "displayName": "Vinh Ngô",
      "photoUrl": "",
      "userId": "16064441220195279473"
     },
     "user_tz": -420
    },
    "id": "905NreuGqO5E",
    "outputId": "a84bfee3-0dc0-4529-9df7-ae10a6c46751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3107,
     "status": "ok",
     "timestamp": 1561997784001,
     "user": {
      "displayName": "Vinh Ngô",
      "photoUrl": "",
      "userId": "16064441220195279473"
     },
     "user_tz": -420
    },
    "id": "rbY7TU5Wt6uV",
    "outputId": "946c46a2-254e-465c-f741-113f7bec1683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3JsYs-FWGqp"
   },
   "source": [
    "___\n",
    "# Normalize data #\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLQ034e2WHJG"
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32) * (1.0 / 255.0) - 0.5\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLa79qihSvbL"
   },
   "source": [
    "___\n",
    "# Read .tfrecords file and get data #\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_waayXbIS3fW"
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "    \n",
    "    files = tf.data.Dataset.list_files(filename_queue)\n",
    "    dataset = files.interleave(tf.data.TFRecordDataset,cycle_length=1)\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "            'old_frame': tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "            'new_frame': tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "            'old_feature_point': tf.io.VarLenFeature( tf.int64),\n",
    "            'new_feature_point':  tf.io.VarLenFeature( tf.int64),\n",
    "            'points_shape':  tf.io.FixedLenFeature([], tf.int64,default_value=0),\n",
    "            'x_mesh': tf.io.VarLenFeature( tf.float32),\n",
    "            'y_mesh': tf.io.VarLenFeature( tf.float32),\n",
    "        }\n",
    "        parsed = tf.parse_single_example(record, keys_to_features)\n",
    "        old_frame_parse = tf.decode_raw(parsed['old_frame'], tf.uint8)\n",
    "        old_frame_parse = tf.reshape(old_frame_parse, [288, 512, 3])\n",
    "        old_frame_parse.set_shape( [288, 512, 3])\n",
    "        new_frame_parse = tf.decode_raw(parsed['new_frame'], tf.uint8)\n",
    "        new_frame_parse = tf.reshape(new_frame_parse,  [288, 512, 3])\n",
    "        new_frame_parse.set_shape( [288, 512, 3])\n",
    "        \n",
    "        #normalize images\n",
    "        old_frame_parse = normalize(old_frame_parse)\n",
    "        new_frame_parse = normalize(new_frame_parse)\n",
    "        input_frames = tf.concat([old_frame_parse,new_frame_parse],1)\n",
    "        ##get feature points shape\n",
    "        #points_shape = tf.cast(parsed['points_shape'], tf.int32)\n",
    "        ##load all feature point of old & new frame\n",
    "        #old_feature_point = tf.cast(tf.sparse.to_dense(parsed['old_feature_point'],default_value = 0),tf.int32)\n",
    "        #old_feature_point = tf.reshape(old_feature_point,[points_shape,2])\n",
    "        #new_feature_point = tf.cast(tf.sparse.to_dense(parsed['new_feature_point'],default_value = 0),tf.int32)\n",
    "        #new_feature_point = tf.reshape(new_feature_point,[points_shape,2])\n",
    "        #load all mesh\n",
    "        #Bắt đầu từ dataset thứ 11 phải chuẩn hóa lại /255 - 0.5\n",
    "        x_mesh = tf.cast(tf.sparse.to_dense(parsed['x_mesh'],default_value = 0),tf.float32)\n",
    "        x_mesh = tf.reshape(x_mesh,[19, 33])\n",
    "        x_mesh = tf.reshape(x_mesh,[19*33])\n",
    "        y_mesh = tf.cast(tf.sparse.to_dense(parsed['y_mesh'],default_value = 0),tf.float32)\n",
    "        y_mesh = tf.reshape(y_mesh,[19, 33])\n",
    "        y_mesh = tf.reshape(y_mesh,[19*33])\n",
    "        groundtruth_mesh = tf.concat([x_mesh,y_mesh],0)\n",
    "        return input_frames,groundtruth_mesh#,old_feature_point, new_feature_point\n",
    "    \n",
    "    #train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=2000)\n",
    "    dataset = dataset.padded_batch(BATCH_SIZE,drop_remainder=True,\n",
    "                                  padded_shapes=([288, 1024, 3],\n",
    "                                                 [19*33*2]))\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    input_frames,groundtruth_mesh = iterator.get_next()\n",
    "    \n",
    "    \n",
    "    return input_frames,groundtruth_mesh#,old_feature_point, new_feature_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF7cChPjV7Y1"
   },
   "source": [
    "___\n",
    "# Loss function #\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdVSx9zpZGc-"
   },
   "source": [
    "## Custom loss 1##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvUwoXhW6rpk"
   },
   "outputs": [],
   "source": [
    "def custom_loss(neighbor_matrix, batch_size):\n",
    "  def Loss(y_true, y_pred):\n",
    "    ## Groundtruth loss\n",
    "    #groundtruth_loss = tf.math.subtract(y_true,y_pred)\n",
    "    #groundtruth_loss = tf.math.square(groundtruth_loss)\n",
    "    #groundtruth_loss = tf.math.reduce_sum(groundtruth_loss,1)\n",
    "    #groundtruth_loss = tf.math.reduce_mean(tf.math.sqrt(groundtruth_loss))/1254.0\n",
    "    \n",
    "    similar_loss = tf.keras.losses.hinge(y_true, y_pred)\n",
    "    ## Similarity loss\n",
    "    ##create prediction matrix size of (batch, max_neighbor, 1254) \n",
    "    #y = tf.identity(y_pred)\n",
    "    #y = tf.reshape(y,[batch_size,1254,1])\n",
    "    #y = tf.tile(y,[1,1,8])\n",
    "    #\n",
    "    #neighbor_index_matrix = tf.reshape(neighbor_matrix,(1,1254,8))\n",
    "    #neighbor_index_matrix = tf.tile(neighbor_index_matrix,[batch_size,1,1])\n",
    "    #neighbor_index_matrix = tf.reshape(neighbor_index_matrix,\n",
    "    #                                   (batch_size,1254,8,1))\n",
    "    #\n",
    "    #batch_index = tf.range(0, batch_size)\n",
    "    #batch_index = tf.reshape(batch_index,[batch_size,1])\n",
    "    #batch_index = tf.tile(batch_index,[1,8])\n",
    "    #batch_index = tf.reshape(batch_index,[batch_size,1,8])\n",
    "    #batch_index = tf.tile(batch_index,[1,1254,1])\n",
    "    #\n",
    "    #batch_index = tf.reshape(batch_index,[batch_size,1254,8,1])\n",
    "    #neighbor_index_matrix = tf.cast(neighbor_index_matrix,tf.int32)\n",
    "    #neighbor_index_matrix = tf.concat([batch_index,neighbor_index_matrix],3)\n",
    "    #neighbor_predict_matrix = tf.gather_nd(y_pred,neighbor_index_matrix)\n",
    "    #\n",
    "    #x_split, y_split = tf.split(neighbor_predict_matrix,2,1)\n",
    "    #\n",
    "    #similar_loss = tf.math.square(tf.math.subtract(x_split,x_predict)) +\\\n",
    "    #                tf.math.square(tf.math.subtract(y_split,y_predict))\n",
    "    #similar_loss = tf.math.sqrt(tf.math.reduce_sum(similar_loss,2))/8.0\n",
    "    ##similar_loss will be shape [4,1254], we still need to reshape it to\n",
    "    ##fit the shape of groundtruth loss\n",
    "    #\n",
    "    #similar_loss = tf.math.reduce_mean(similar_loss)\n",
    "    \n",
    "    # Feature loss\n",
    "    \n",
    "    #num_feature_points = tf.shape(old_feature_point)[1]\n",
    "    #  #old_point\n",
    "    #old_points = tf.reshape(old_feature_point,\n",
    "    #                        [batch_size,1,num_feature_points,2])\n",
    "    #old_points = tf.tile(old_points,[1,9,1,1])\n",
    "    #old_points = tf.cast(old_points,tf.float32)\n",
    "    #  #new_point\n",
    "    #new_points = tf.reshape(new_feature_point,\n",
    "    #                        [batch_size,1,num_feature_points,2])\n",
    "    #\n",
    "    #new_points = tf.tile(new_points,[1,9,1,1])\n",
    "    #new_points = tf.cast(new_points,tf.float32)\n",
    "    #  #get motion\n",
    "    #motion = tf.identity(y_pred)\n",
    "    #x_original_meshes = tf.slice(motion,[0,0],[batch_size,627])\n",
    "    #y_original_meshes = tf.slice(motion,[0,627],[batch_size,627])\n",
    "    #\n",
    "    #downsample_meshes = tf.constant([0,16,32,\n",
    "    #                                   9*33,9*33+16,9*33+32,\n",
    "    #                                   18*33,18*33+16,18*33+32])\n",
    "    #downsample_meshes = tf.reshape(downsample_meshes,[1,9])\n",
    "    #downsample_meshes = tf.tile(downsample_meshes,[batch_size,1])\n",
    "    #downsample_meshes = tf.reshape(downsample_meshes,[batch_size,9,1])\n",
    "    #\n",
    "    #batch_index = tf.range(0, batch_size)\n",
    "    #batch_index = tf.reshape(batch_index,[batch_size,1])\n",
    "    #batch_index = tf.tile(batch_index,[1,9])\n",
    "    #batch_index = tf.reshape(batch_index,[batch_size,9,1])\n",
    "    #\n",
    "    #downsample_meshes = tf.concat([batch_index,downsample_meshes],2)\n",
    "    #x_downsample_motion_meshes =tf.gather_nd(x_original_meshes,\n",
    "    #                                         downsample_meshes)/512.0\n",
    "    #y_downsample_motion_meshes = tf.gather_nd(y_original_meshes,\n",
    "    #                                          downsample_meshes)/288.0\n",
    "    #x_downsample_motion_meshes = tf.reshape(x_downsample_motion_meshes,\n",
    "    #                                        [batch_size,9,1])\n",
    "    #y_downsample_motion_meshes = tf.reshape(y_downsample_motion_meshes,\n",
    "    #                                        [batch_size,9,1])\n",
    "    #motion = tf.concat([x_downsample_motion_meshes, y_downsample_motion_meshes],\n",
    "    #                   2)\n",
    "    #motion = tf.reshape(motion,[batch_size,9,1,2])\n",
    "    #motion = tf.tile(motion,[1,1,num_feature_points,1])\n",
    "    #pred_location = tf.multiply(old_points,(motion+1.0))\n",
    "    #\n",
    "    #feature_loss = tf.math.subtract(pred_location,new_points)\n",
    "    #feature_loss = tf.math.square(feature_loss)\n",
    "    #feature_loss = tf.math.reduce_sum(feature_loss,axis=3)\n",
    "    #feature_loss = tf.math.sqrt(tf.math.reduce_sum(feature_loss))\\\n",
    "    #                /tf.cast(num_feature_points,tf.float32) \n",
    "    ##shape (batch,9)\n",
    "    #feature_loss = tf.math.reduce_mean(feature_loss)\n",
    "    # similar_loss ++feature_loss\n",
    "    return   similar_loss #+ 50*groundtruth_loss#+feature_loss\n",
    "  return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OR5oTyFWeoil"
   },
   "source": [
    "# Learning rate schedule #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RzzytKKYVdu"
   },
   "outputs": [],
   "source": [
    "NUM_ITERATION_PER_EPOCH = 100*2*2\n",
    "\n",
    "def schedule(epoch, lr):\n",
    "  iteration = epoch*NUM_ITERATION_PER_EPOCH\n",
    "  decay_step = 30000\n",
    "  if iteration /decay_step >= 1 and (iteration-(iteration%decay_step)\n",
    "                                     *decay_step - NUM_ITERATION_PER_EPOCH) <0:\n",
    "        return lr*0.1\n",
    "  else:\n",
    "    return lr\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(schedule,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lv6Jyr7bP6S0"
   },
   "outputs": [],
   "source": [
    "def Create_model():\n",
    "  base_model = ResNet50(weights= 'imagenet', include_top=False, \n",
    "                        input_shape= (288,1024,3))\n",
    "  \n",
    "  model = Sequential([base_model,\n",
    "                      Flatten(),\n",
    "                     Dense(256,activation='relu'),\n",
    "                      Dense(128,activation='relu'),\n",
    "                      #Dense(512,activation='relu'),\n",
    "                     Dense(19*33*2,activation=\"linear\")])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zg4VsUw-S7ng"
   },
   "source": [
    "___\n",
    "# Main procedure #\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dT4OOj11ec5y"
   },
   "source": [
    "## Load training and validation data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1561997812248,
     "user": {
      "displayName": "Vinh Ngô",
      "photoUrl": "",
      "userId": "16064441220195279473"
     },
     "user_tz": -420
    },
    "id": "sIuL5-9wY79P",
    "outputId": "d5f3b40b-b253-4c71-872b-a8beb6927791"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 16:16:51.232580 140165084358528 deprecation.py:323] From <ipython-input-4-67ede45fdc95>:52: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "input_frames,groundtruth_mesh\\\n",
    "= read_and_decode('./gdrive/My Drive/Dataset3/Train/*.tfrecords')\n",
    "validate_input_frames,validate_groundtruth_mesh\\\n",
    "= read_and_decode('./gdrive/My Drive/Dataset3/Validate/*.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDDDtgkKkolG"
   },
   "source": [
    "## Initial training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 212734,
     "status": "ok",
     "timestamp": 1561998054256,
     "user": {
      "displayName": "Vinh Ngô",
      "photoUrl": "",
      "userId": "16064441220195279473"
     },
     "user_tz": -420
    },
    "id": "gaeD2rIPPETB",
    "outputId": "afdb13a5-9728-4c1a-faae-71b3d85aeb9d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0701 16:17:33.444319 140165084358528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 9, 32, 2048)       23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 589824)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               150995200 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1254)              161766    \n",
      "=================================================================\n",
      "Total params: 174,777,574\n",
      "Trainable params: 174,724,454\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "399/400 [============================>.] - ETA: 0s - loss: 1.1110\n",
      "Epoch 00001: val_loss improved from inf to 0.97929, saving model to ./gdrive/My Drive/model.h5\n",
      "400/400 [==============================] - 185s 464ms/step - loss: 1.1101 - val_loss: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f79a8232cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_STEPS = 100*2*2\n",
    "VALIDATION_STEPS = 20*2*2\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./gdrive/My Drive/model.h5',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "\n",
    "#Combine callbacks\n",
    "callbacks_list = [checkpoint,lrate]\n",
    "opt=tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9,beta_2=0.999)\n",
    "model = Create_model()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=custom_loss(Get_Neighbor_Matrix(), BATCH_SIZE))\n",
    "#,old_feature_point,new_feature_point\n",
    "model.summary()\n",
    "model.fit(input_frames, groundtruth_mesh,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs=1,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_steps = VALIDATION_STEPS,\n",
    "          validation_data = (validate_input_frames,validate_groundtruth_mesh),\n",
    "          steps_per_epoch = TRAIN_STEPS)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "#del X\n",
    "gc.collect()\n",
    "#model.save_weights('./gdrive/My Drive/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8jaheJ0c9el"
   },
   "source": [
    "## Cotinue train from save weight ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "id": "AkwlkP6sySMd",
    "outputId": "99ab72e9-e7e0-44ec-c822-ee451a811c63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 16:13:50.092340 140005571860352 deprecation.py:323] From <ipython-input-4-67ede45fdc95>:52: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0701 16:13:58.103060 140005571860352 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0701 16:14:05.697452 140005571860352 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 9.999999747378752e-06.\n",
      "280/400 [====================>.........] - ETA: 50s - loss: 0.9566"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 100*2*2\n",
    "VALIDATION_STEPS = 20*2*2\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./gdrive/My Drive/model13.h5',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "\n",
    "#Combine callbacks\n",
    "callbacks_list = [checkpoint,lrate]\n",
    "opt=tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9,beta_2=0.999)\n",
    "input_frames1,groundtruth_mesh1\\\n",
    "= read_and_decode('./gdrive/My Drive/Dataset3/Train13/*.tfrecords')\n",
    "validate_input_frames1,validate_groundtruth_mesh1\\\n",
    "= read_and_decode('./gdrive/My Drive/Dataset3/Validate13/*.tfrecords')\n",
    "\n",
    "weights_path = './gdrive/My Drive/model12.h5'\n",
    "model1 = Create_model()\n",
    "model1.load_weights(weights_path)\n",
    "model1.compile(optimizer=opt,\n",
    "              loss=custom_loss(Get_Neighbor_Matrix(), \n",
    "              BATCH_SIZE))\n",
    "model1.fit(input_frames1, groundtruth_mesh1,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs=1,\n",
    "          callbacks=callbacks_list,\n",
    "           validation_steps = VALIDATION_STEPS,\n",
    "          validation_data = (validate_input_frames1,validate_groundtruth_mesh1),\n",
    "          steps_per_epoch = TRAIN_STEPS)#,validation_split=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDYkpsxHDH5W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
